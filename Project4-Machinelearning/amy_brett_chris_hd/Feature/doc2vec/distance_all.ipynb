{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### no brand names and search terms vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext Cython\n"
     ]
    }
   ],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 223 ms, sys: 570 ms, total: 793 ms\n",
      "Wall time: 1.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%cython\n",
    "from gensim.models import doc2vec\n",
    "import nltk\n",
    "import re\n",
    "def split_sentence (sentence):\n",
    "    return re.split('\\W+',sentence)\n",
    "    \n",
    "class MyDocs(object):\n",
    "    def __iter__(self):\n",
    "        for i, text in enumerate(open(\"txt_all_nb.txt\")): # doesn't use brand name\n",
    "            yield doc2vec.LabeledSentence(words=split_sentence(text), tags=['%s' % i])\n",
    "            # Train the doc2vec model\n",
    "cdef desp = MyDocs()\n",
    "model = doc2vec.Doc2Vec(desp, size = 200, window = 8, min_count = 5, workers = 4)\n",
    "model.save('distance_all.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = doc2vec.Doc2Vec.load('distance_all.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02200266,  0.01908584,  0.00845405, ..., -0.00358907,\n",
       "         0.00019054, -0.02040428],\n",
       "       [ 0.06066574,  0.0153622 , -0.00077939, ...,  0.02107242,\n",
       "        -0.00973943, -0.01212798],\n",
       "       [ 0.03206712, -0.00783784, -0.00156679, ...,  0.02957773,\n",
       "         0.00123606,  0.00124532],\n",
       "       ..., \n",
       "       [ 0.06754978, -0.00714241, -0.01753183, ...,  0.02170464,\n",
       "        -0.02912914,  0.03379539],\n",
       "       [ 0.08341395,  0.01464552,  0.02370741, ...,  0.0169495 ,\n",
       "        -0.05061054,  0.02032607],\n",
       "       [ 0.01601431,  0.01445545,  0.01292743, ..., -0.00069231,\n",
       "        -0.02125877,  0.02262981]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the vector of search term according to our model\n",
    "#def input_vec(x):\n",
    "#    model.infer_vector(split_sentence(x))\n",
    "# map(input_vec,open(\"txt_st.txt))\n",
    "import numpy as np\n",
    "pt_arrays = np.zeros((240760, 200))\n",
    "for i,text in enumerate(open(\"txt_pt.txt\")): # input search terms \n",
    "    pt_arrays[i]=model.infer_vector(split_sentence(text))   \n",
    "pt_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03758235, -0.08407412,  0.01892379, ...,  0.08160976,\n",
       "        -0.01337415, -0.01347442],\n",
       "       [ 0.04961559, -0.0095962 ,  0.00637948, ...,  0.06713269,\n",
       "        -0.01257816, -0.00704337],\n",
       "       [ 0.02635622,  0.0104771 , -0.01161926, ..., -0.01538065,\n",
       "         0.00028396,  0.02770254],\n",
       "       ..., \n",
       "       [-0.00763746, -0.03730408, -0.01154349, ...,  0.03627979,\n",
       "         0.00559608,  0.03310749],\n",
       "       [ 0.02992605,  0.04820156,  0.04666499, ...,  0.0133902 ,\n",
       "         0.0107386 ,  0.00317763],\n",
       "       [ 0.04723874, -0.01256068,  0.01744816, ...,  0.00654965,\n",
       "         0.00027499, -0.01290956]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "st_arrays = np.zeros((240760, 200))\n",
    "for i,text in enumerate(open(\"txt_st.txt\")): # input search terms \n",
    "    st_arrays[i]=model.infer_vector(split_sentence(text))   \n",
    "st_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## calculate the cosin distance between 2 vectors to generate the 3rd features\n",
    "# Compute the cosine similarity values between the input text and all archived reviews\n",
    "# cossims_with_input = map(lambda v: cossim(input_vec, v), model.docvecs) \n",
    "# need to chaneg the code into rows: calculate the cosin distance between the vectors in same rows\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Calculate the cosine similarity between two vecotrs \n",
    "def cossim(v1, v2):\n",
    "    return np.dot(v1, v2) / np.sqrt(np.dot(v1, v1)) / np.sqrt(np.dot(v2, v2))\n",
    "\n",
    "cossims_with_st=np.zeros((240760,1))\n",
    "for i in range(240760):\n",
    "    cossims_with_st[i] = cossim(st_arrays[i], pt_arrays[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"distance_all.csv\",cossims_with_st, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.039928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.407894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.214059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.166730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.437700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.471011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.180338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.054024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.092775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.338710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.319586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.311754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.042323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.264092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.134399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.078368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.025957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.034809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.052255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.093277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.050645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.122900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.122534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.114991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.200534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.327111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.492246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.047657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.194234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.226084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240730</th>\n",
       "      <td>0.331633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240731</th>\n",
       "      <td>0.303265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240732</th>\n",
       "      <td>0.326466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240733</th>\n",
       "      <td>0.153123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240734</th>\n",
       "      <td>0.306898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240735</th>\n",
       "      <td>0.167936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240736</th>\n",
       "      <td>0.186922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240737</th>\n",
       "      <td>0.181756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240738</th>\n",
       "      <td>0.085300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240739</th>\n",
       "      <td>0.020402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240740</th>\n",
       "      <td>0.476250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240741</th>\n",
       "      <td>0.149993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240742</th>\n",
       "      <td>0.538936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240743</th>\n",
       "      <td>0.065885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240744</th>\n",
       "      <td>0.171330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240745</th>\n",
       "      <td>0.016406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240746</th>\n",
       "      <td>0.343196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240747</th>\n",
       "      <td>0.035921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240748</th>\n",
       "      <td>0.393094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240749</th>\n",
       "      <td>0.351139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240750</th>\n",
       "      <td>0.054112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240751</th>\n",
       "      <td>0.318110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240752</th>\n",
       "      <td>0.136453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240753</th>\n",
       "      <td>0.279470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240754</th>\n",
       "      <td>0.109659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240755</th>\n",
       "      <td>0.038278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240756</th>\n",
       "      <td>0.039078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240757</th>\n",
       "      <td>0.101838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240758</th>\n",
       "      <td>0.588906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240759</th>\n",
       "      <td>0.236097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240760 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "0      -0.039928\n",
       "1       0.407894\n",
       "2       0.214059\n",
       "3       0.166730\n",
       "4       0.437700\n",
       "5       0.471011\n",
       "6       0.180338\n",
       "7      -0.054024\n",
       "8       0.092775\n",
       "9       0.338710\n",
       "10      0.319586\n",
       "11      0.311754\n",
       "12      0.042323\n",
       "13      0.264092\n",
       "14      0.134399\n",
       "15      0.078368\n",
       "16      0.025957\n",
       "17     -0.034809\n",
       "18     -0.052255\n",
       "19      0.093277\n",
       "20     -0.050645\n",
       "21      0.122900\n",
       "22      0.122534\n",
       "23      0.114991\n",
       "24     -0.200534\n",
       "25      0.327111\n",
       "26      0.492246\n",
       "27     -0.047657\n",
       "28      0.194234\n",
       "29      0.226084\n",
       "...          ...\n",
       "240730  0.331633\n",
       "240731  0.303265\n",
       "240732  0.326466\n",
       "240733  0.153123\n",
       "240734  0.306898\n",
       "240735  0.167936\n",
       "240736  0.186922\n",
       "240737  0.181756\n",
       "240738  0.085300\n",
       "240739  0.020402\n",
       "240740  0.476250\n",
       "240741  0.149993\n",
       "240742  0.538936\n",
       "240743  0.065885\n",
       "240744  0.171330\n",
       "240745  0.016406\n",
       "240746  0.343196\n",
       "240747  0.035921\n",
       "240748  0.393094\n",
       "240749  0.351139\n",
       "240750  0.054112\n",
       "240751  0.318110\n",
       "240752  0.136453\n",
       "240753  0.279470\n",
       "240754  0.109659\n",
       "240755  0.038278\n",
       "240756  0.039078\n",
       "240757  0.101838\n",
       "240758  0.588906\n",
       "240759  0.236097\n",
       "\n",
       "[240760 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coswithst=pd.read_csv(\"distance_all.csv\",header=None)\n",
    "coswithst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cws_trn=coswithst.iloc[:num_train]\n",
    "cws_tst=coswithst.iloc[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
